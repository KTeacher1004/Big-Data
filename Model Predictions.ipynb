{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31bc8f87",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4af947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 3060\n",
      "Loaded stars tensor from joblib.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bazen\\AppData\\Local\\Temp\\ipykernel_10300\\4180099715.py:88: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  amp = torch.cuda.amp.autocast(dtype=torch.float16) if device==\"cuda\" else torch.no_grad()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70986e48df7b43bba4e1162e94f1211d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b444acdeff514841823c953397c90e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad1d9e0f85b43f1a6a9a6292d080fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26c5a3b27f5459a9f18af9e3d371b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b67f93c57654cae9b09def8dc13ed39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316e03b5dc4e4f339d0e4fb560ecf9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627aea0817d7420e90508b0c6972678e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35387cd7204c49aab7a0a5d7d2fc7176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5eb304956b44ae68c88e172cc3b0465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb09c34d80f543f2a4787abdb14874cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f413f9034147d19a13a56e3a7b8be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4e67017f30427888765370d009801f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffda6527ba94076b0ee575872ea453e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295e0cbe29804a07bc68347ea0db7a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62ed8e00ea24598bbb9cbd449146c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6160af31d5b74895aae5e38b82b89fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6dac6ab5e1490aa5c3a995192cc34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ff89e1aa47450ab07bd572ec828123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282f7da94f324109aa60331e230ce99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814aaa21e5044d7ba419ae355eb72f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb1b9823c2d4646bc92175ea8537483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efb588d453d4e2eb249595e3df2c454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5bc45f9b7d54770b4aa769c3ac38461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655c41ebfa7643049e46475a3e9a79a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec373a27a8e45789cfabfa94e218c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68ce063fe5440faba8fbd55524b2d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         asin  true_rating  pred_rating  ratings_total  n_texts  \\\n",
      "0  B0FG4MGVJP          4.6     4.534182            873        9   \n",
      "1  B0947BJ67M          4.1     4.253288           3962        9   \n",
      "2  B0DZDC3WW5          4.8     4.563303           2375        9   \n",
      "3  B0FLXTK4HL          4.4     3.851171            418        9   \n",
      "4  B0FLKNZJ1H          4.2     4.297025            250        9   \n",
      "\n",
      "                                         sample_text  \n",
      "0  HP Newly Designed 15.6'' Business Laptop(2025/...  \n",
      "1  HP 14 Laptop, Intel Celeron N4020, 4 GB RAM, 6...  \n",
      "2  Apple 2025 MacBook Air 13-inch Laptop with M4 ...  \n",
      "3  HP 15.6\" FHD Laptop Computer for Home Business...  \n",
      "4  HP Student and Home Laptop with Free Microsoft...  \n",
      "\n",
      "Overall product-level metrics:\n",
      "{'MAE': 0.3308239281177521, 'RMSE': 0.39441946148872375, 'Within_0.5': 0.6923076923076923, 'Within_1.0': 1.0}\n",
      "\n",
      "Top 10 largest errors:\n",
      "          asin  true_rating  pred_rating   abs_err  n_texts  \\\n",
      "21  B0DYQM4BDB          4.4     3.619953  0.780047        9   \n",
      "6   B0F6PLQ93N          4.6     3.913536  0.686464        9   \n",
      "22  B0FHYCR41F          4.0     4.615119  0.615119        9   \n",
      "3   B0FLXTK4HL          4.4     3.851171  0.548829        9   \n",
      "20  B0CVS18PH9          4.6     4.057377  0.542623        9   \n",
      "9   B0DW1FVPK8          4.4     3.861127  0.538873        9   \n",
      "5   B0DZZWMB2L          4.5     3.961759  0.538241        9   \n",
      "12  B0DLHBYRPS          4.8     4.274712  0.525288        9   \n",
      "23  B0CV9VGMPT          4.1     3.694278  0.405722        9   \n",
      "16  B0F19KLHG3          4.2     4.600658  0.400658        9   \n",
      "\n",
      "                                          sample_text  \n",
      "21  LG 65-Inch Class OLED evo AI 4K C5 Series Smar...  \n",
      "6   Acer Nitro V Gaming Laptop | Intel Core i7-136...  \n",
      "22  Sony 77 Inch OLED 4K Ultra HD TV BRAVIA XR8B S...  \n",
      "3   HP 15.6\" FHD Laptop Computer for Home Business...  \n",
      "20  LG 65-Inch Class OLED evo C4 Series Smart TV 4...  \n",
      "9   ASUS ROG Strix G16 (2025) Gaming Laptop, 16” R...  \n",
      "5   ASUS ROG Strix G16 (2025) Gaming Laptop, 16” F...  \n",
      "12  Apple 2024 MacBook Pro Laptop with M4 chip wit...  \n",
      "23  Samsung 65-Inch Class OLED 4K S90D Series HDR+...  \n",
      "16  INSIGNIA 50\" Class F50 Series LED 4K UHD Smart...  \n",
      "\n",
      "Saved 26 rows to product_catalog_scores.csv\n"
     ]
    }
   ],
   "source": [
    "# NEW NOTEBOOK: load saved nlptown model and score ALL products in product_catalog\n",
    "\n",
    "import os, re, html, numpy as np, pandas as pd, pymongo, torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# ---------- paths / config ----------\n",
    "LOAD_DIR = r\"nlptown_model\"\n",
    "MONGO_URI = os.getenv(\n",
    "    \"MONGO_URI\",\n",
    "    \"mongodb+srv://admin:adminpassword@assignment3.dhfn7vh.mongodb.net/?retryWrites=true&w=majority&appName=Assignment3\"\n",
    ")\n",
    "DB_NAME = \"Assignment3\"\n",
    "PRODUCT_COLL = \"product_catalog\"\n",
    "\n",
    "BATCH_SZ = 256    # drop to 128/64 if you hit OOM\n",
    "MAX_LEN  = 128\n",
    "\n",
    "# ---------- device ----------\n",
    "for k in (\"CUDA_VISIBLE_DEVICES\", \"CUDA_DEVICE_ORDER\"):\n",
    "    os.environ.pop(k, None)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if DEVICE==\"cuda\" else \"CPU\")\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ---------- mongo ----------\n",
    "client = pymongo.MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def clean_text(s):\n",
    "    if not s: return \"\"\n",
    "    s = html.unescape(s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def stars_tensor_from_id2label(model, device):\n",
    "    id2label = getattr(model.config, \"id2label\", {})\n",
    "    stars = []\n",
    "    for i in range(model.config.num_labels):\n",
    "        lbl = str(id2label.get(i, f\"LABEL_{i}\")).lower().strip()\n",
    "        m = re.match(r\"^\\s*(\\d+)\\s*stars?$\", lbl)\n",
    "        if m:\n",
    "            stars.append(int(m.group(1)))\n",
    "        else:\n",
    "            m2 = re.match(r\"^\\s*label[_\\s-]?(\\d+)\\s*$\", lbl)\n",
    "            stars.append(int(m2.group(1)) + 1 if m2 else (i + 1))\n",
    "    return torch.tensor(stars, dtype=torch.float32, device=device)\n",
    "\n",
    "def eval_metrics(y_true, y_pred):\n",
    "    y_true = np.array(y_true, dtype=np.float32)\n",
    "    y_pred = np.clip(np.array(y_pred, dtype=np.float32), 1.0, 5.0)\n",
    "    err = np.abs(y_true - y_pred)\n",
    "    return {\n",
    "        \"MAE\": float(err.mean()),\n",
    "        \"RMSE\": float(np.sqrt(((y_true - y_pred)**2).mean())),\n",
    "        \"Within_0.5\": float((err <= 0.5).mean()),\n",
    "        \"Within_1.0\": float((err <= 1.0).mean()),\n",
    "    }\n",
    "\n",
    "# ---------- load tokenizer/model/KS from your folder ----------\n",
    "tok = AutoTokenizer.from_pretrained(LOAD_DIR)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(LOAD_DIR).to(DEVICE).eval()\n",
    "if DEVICE == \"cuda\":\n",
    "    model = model.half()\n",
    "\n",
    "# stars tensor: prefer joblib file if present, else rebuild\n",
    "KS = None\n",
    "stars_joblib = os.path.join(LOAD_DIR, \"stars_tensor.joblib\")\n",
    "if os.path.exists(stars_joblib):\n",
    "    try:\n",
    "        import joblib  # may not be in this env; that's fine, we'll fall back\n",
    "        KS = torch.tensor(joblib.load(stars_joblib), dtype=torch.float32, device=DEVICE)\n",
    "        print(\"Loaded stars tensor from joblib.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load stars_tensor.joblib ({e}); rebuilding from id2label…\")\n",
    "if KS is None:\n",
    "    KS = stars_tensor_from_id2label(model, DEVICE)\n",
    "    print(\"Built stars tensor from id2label:\", KS.tolist())\n",
    "\n",
    "# ---------- prediction ----------\n",
    "def predict_expected_stars(texts, batch_size=BATCH_SZ, max_length=MAX_LEN, device=DEVICE):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        amp = torch.cuda.amp.autocast(dtype=torch.float16) if device==\"cuda\" else torch.no_grad()\n",
    "        with amp:\n",
    "            for i in tqdm(range(0, len(texts), batch_size),\n",
    "                          total=(len(texts)+batch_size-1)//batch_size,\n",
    "                          desc=\"Infer\"):\n",
    "                chunk = texts[i:i+batch_size]\n",
    "                # coerce to valid strings\n",
    "                chunk = [clean_text(c if isinstance(c, str) else str(c) if c is not None else \"\") or \".\"\n",
    "                         for c in chunk]\n",
    "                enc = tok(chunk, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "                enc = {k: v.to(device) for k, v in enc.items()}\n",
    "                logits = model(**enc).logits.float()\n",
    "                probs  = torch.softmax(logits, dim=-1)\n",
    "                exp    = (probs * KS).sum(dim=1).cpu().numpy()\n",
    "                preds.extend(exp.tolist())\n",
    "    return preds\n",
    "\n",
    "def product_texts_from_doc(doc, include_product_title=True):\n",
    "    texts = []\n",
    "    if include_product_title:\n",
    "        pt = doc.get(\"product_title\") or \"\"\n",
    "        if isinstance(pt, str) and pt.strip():\n",
    "            texts.append(clean_text(pt))\n",
    "    titles = ((doc.get(\"product_review\") or {}).get(\"titles\") or [])\n",
    "    for t in titles:\n",
    "        t = clean_text(str(t)) if t else \"\"\n",
    "        if t:\n",
    "            texts.append(t)\n",
    "    return texts or [\".\"]\n",
    "\n",
    "def predict_product_rating(doc):\n",
    "    texts = product_texts_from_doc(doc, include_product_title=True)\n",
    "    preds = predict_expected_stars(texts)\n",
    "    return float(np.mean(preds))\n",
    "\n",
    "# ---------- run over the whole product_catalog ----------\n",
    "def score_product_catalog(limit=None):\n",
    "    proj = {\"asin\":1,\"product_title\":1,\"product_review.titles\":1,\"rating\":1,\"ratings_total\":1}\n",
    "    cur = db[PRODUCT_COLL].find({\"rating\":{\"$exists\":True}}, proj, batch_size=256)\n",
    "    if limit:\n",
    "        cur = cur.limit(int(limit))\n",
    "    rows = []\n",
    "    for d in cur:\n",
    "        try:\n",
    "            true_rating = float(d.get(\"rating\"))\n",
    "        except:\n",
    "            continue\n",
    "        pred_rating = predict_product_rating(d)\n",
    "        rows.append({\n",
    "            \"asin\": d.get(\"asin\"),\n",
    "            \"true_rating\": true_rating,\n",
    "            \"pred_rating\": float(np.clip(pred_rating, 1.0, 5.0)),\n",
    "            \"ratings_total\": d.get(\"ratings_total\", None),\n",
    "            \"n_texts\": len(product_texts_from_doc(d)),\n",
    "            \"sample_text\": (product_texts_from_doc(d)[0])[:140],\n",
    "        })\n",
    "    try:\n",
    "        cur.close()\n",
    "    except:\n",
    "        pass\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ---------- execute ----------\n",
    "df = score_product_catalog(limit=None)   # set to a small number (e.g., 200) to test first\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nOverall product-level metrics:\")\n",
    "print(eval_metrics(df[\"true_rating\"].values, df[\"pred_rating\"].values))\n",
    "\n",
    "# Largest absolute errors to inspect\n",
    "df[\"abs_err\"] = (df[\"true_rating\"] - df[\"pred_rating\"]).abs()\n",
    "print(\"\\nTop 10 largest errors:\")\n",
    "print(df.sort_values(\"abs_err\", ascending=False).head(10)[[\"asin\",\"true_rating\",\"pred_rating\",\"abs_err\",\"n_texts\",\"sample_text\"]])\n",
    "\n",
    "out_path = \"product_catalog_scores.csv\"\n",
    "df[[\"asin\", \"true_rating\", \"pred_rating\"]].to_csv(out_path, index=False)\n",
    "print(f\"\\nSaved {len(df)} rows to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23410b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions upserted=26, modified=0\n",
      "metrics saved: {'MAE': 0.3308239281177521, 'RMSE': 0.39441946148872375, 'Within_0.5': 0.6923076923076923, 'Within_1.0': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Push predictions + run metrics to a separate MongoDB (for Charts)\n",
    "\n",
    "import pymongo, numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# --- target Charts cluster (change DB/COL names if you like) ---\n",
    "CHARTS_URI = \"mongodb+srv://admin:adminpassword@cluster0.42o5xip.mongodb.net/?retryWrites=true&w=majority&appName=Charts\"\n",
    "CHARTS_DB  = \"assignment3_charts\"         # <- choose any db name on the Charts cluster\n",
    "PRED_COLL  = \"product_predictions\"         # per-product predictions\n",
    "METR_COLL  = \"model_run_metrics\"           # one doc per run with summary metrics\n",
    "\n",
    "# --- connect ---\n",
    "charts_client = pymongo.MongoClient(CHARTS_URI)\n",
    "charts_db = charts_client[CHARTS_DB]\n",
    "\n",
    "# --- prepare prediction docs (minimal + a few handy derived fields) ---\n",
    "df_save = df[[\"asin\", \"true_rating\", \"pred_rating\"]].copy()\n",
    "df_save[\"abs_err\"]    = (df_save[\"true_rating\"] - df_save[\"pred_rating\"]).abs()\n",
    "df_save[\"signed_err\"] = (df_save[\"pred_rating\"] - df_save[\"true_rating\"])\n",
    "df_save[\"true_bin\"]   = df_save[\"true_rating\"].round().astype(int)\n",
    "df_save[\"pred_bin\"]   = df_save[\"pred_rating\"].round().astype(int)\n",
    "df_save[\"run_ts\"]     = datetime.utcnow()\n",
    "df_save[\"model\"]      = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "# --- upsert predictions by asin ---\n",
    "ops = [\n",
    "    pymongo.ReplaceOne({\"asin\": rec[\"asin\"]}, rec, upsert=True)\n",
    "    for rec in df_save.to_dict(orient=\"records\")\n",
    "]\n",
    "res = charts_db[PRED_COLL].bulk_write(ops, ordered=False)\n",
    "print(f\"predictions upserted={res.upserted_count}, modified={res.modified_count}\")\n",
    "\n",
    "# --- indexes (first run only; harmless if they exist) ---\n",
    "charts_db[PRED_COLL].create_index([(\"asin\", 1)], unique=True)\n",
    "charts_db[PRED_COLL].create_index([(\"run_ts\", -1)])\n",
    "charts_db[PRED_COLL].create_index([(\"true_bin\", 1), (\"pred_bin\", 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26b8a7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics saved: {'MAE': 0.3308239281177521, 'RMSE': 0.39441946148872375, 'pct_within_0_5': 69.23, 'pct_within_1_0': 100.0}\n"
     ]
    }
   ],
   "source": [
    "m = eval_metrics(df_save[\"true_rating\"].values, df_save[\"pred_rating\"].values)\n",
    "\n",
    "# convert to percentages (numeric) and use dot-safe keys\n",
    "m[\"pct_within_0_5\"] = round(m.get(\"Within_0.5\", 0) * 100, 2)\n",
    "m[\"pct_within_1_0\"] = round(m.get(\"Within_1.0\", 0) * 100, 2)\n",
    "\n",
    "# (optional) drop the old dotted keys if they exist in m\n",
    "m.pop(\"Within_0.5\", None)\n",
    "m.pop(\"Within_1.0\", None)\n",
    "\n",
    "m_doc = {\n",
    "    \"_ts\": datetime.utcnow(),\n",
    "    \"model\": \"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    \"dataset\": \"product_catalog\",\n",
    "    \"count\": int(len(df_save)),\n",
    "    \"metrics\": m,\n",
    "}\n",
    "charts_db[METR_COLL].insert_one(m_doc)\n",
    "print(\"metrics saved:\", m_doc[\"metrics\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
